{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD3cDtuB4PHS"
   },
   "source": [
    "# **SBERT-Based Multi-label Emotion Classifier with NRC-VAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries (ensure these are all installed)\n",
    "!pip install -q git+https://github.com/trent-b/iterative-stratification.git\n",
    "!pip install -q transformers torch scikit-learn pandas numpy matplotlib seaborn accelerate Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from accelerate import Accelerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from pathlib import Path\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from google.colab import files\n",
    "import json\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Grouping hyperparameters and settings here improves readability and maintainability\n",
    "class Config:\n",
    "    DATA_PATH = \"balanced_df.csv\"\n",
    "    VAD_LEXICON_PATH = \"NRC-VAD-Lexicon.txt\"\n",
    "    MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    MAX_LENGTH = 256\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 2e-5\n",
    "    NUM_EPOCHS = 15\n",
    "    DROPOUT_RATE = 0.3\n",
    "    N_SPLITS = 5\n",
    "    RANDOM_STATE = 42\n",
    "    THRESHOLD = 0.5\n",
    "    CHECKPOINT_DIR = \"checkpoints/best_model\"\n",
    "    OUTPUT_DIR = \"outputs\"\n",
    "    PDF_FILENAME = \"evaluation_plots.pdf\"\n",
    "    MODEL_ZIP_FILENAME = \"best_model.zip\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# --- Create Output Directory ---\n",
    "Path(config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(config.CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading and Initial Preprocessing ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    balanced_df = pd.read_csv(config.DATA_PATH)\n",
    "    nrc_vad = pd.read_csv(config.VAD_LEXICON_PATH, sep='\\t')\n",
    "    nrc_vad.columns = [\"word\", \"valence\", \"arousal\", \"dominance\"]\n",
    "    nrc_vad.set_index(\"word\", inplace=True)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data file: {e}. Please ensure '{config.DATA_PATH}' and '{config.VAD_LEXICON_PATH}' exist.\")\n",
    "    # Exit or raise exception if critical files are missing\n",
    "    raise e\n",
    "\n",
    "print(\"Preprocessing data...\")\n",
    "balanced_df = balanced_df.dropna(subset=[\"utterance\", \"emotion\"])\n",
    "balanced_df = balanced_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert comma-separated string to list of emotions\n",
    "def parse_emotions(emotion_str):\n",
    "    if isinstance(emotion_str, str):\n",
    "        return [e.strip() for e in emotion_str.split(',')]\n",
    "    elif isinstance(emotion_str, list): # Already a list\n",
    "         return emotion_str\n",
    "    else:\n",
    "        return [] # Handle unexpected types\n",
    "\n",
    "balanced_df['emotion'] = balanced_df['emotion'].apply(parse_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Engineering (VAD) ---\n",
    "print(\"Computing VAD features...\")\n",
    "def compute_vad_features(text, vad_lexicon):\n",
    "    tokens = text.lower().split()\n",
    "    vad_values = []\n",
    "    for token in tokens:\n",
    "        if token in vad_lexicon.index:\n",
    "            vad_values.append(vad_lexicon.loc[token])\n",
    "    if vad_values:\n",
    "        mean_vad = pd.DataFrame(vad_values).mean().values\n",
    "    else:\n",
    "        mean_vad = np.zeros(3)\n",
    "    return mean_vad\n",
    "\n",
    "# Apply the function\n",
    "vad_features = np.vstack(balanced_df['utterance'].apply(lambda text: compute_vad_features(text, nrc_vad)))\n",
    "\n",
    "\n",
    "# --- Label Binarization ---\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(balanced_df['emotion'])\n",
    "utterances = balanced_df['utterance'].tolist()\n",
    "label_names = mlb.classes_\n",
    "num_labels = len(label_names)\n",
    "print(f\"Found {num_labels} unique labels: {label_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Exploratory Data Analysis (EDA) ---\n",
    "print(\"\\n--- EDA ---\")\n",
    "print(f\"Total samples in dataset: {len(balanced_df)}\")\n",
    "\n",
    "# 1. Emotion Distribution (Original)\n",
    "all_emotions = [emo for sublist in balanced_df['emotion'] for emo in sublist if sublist] # Check if sublist is not empty\n",
    "emotion_counts = Counter(all_emotions)\n",
    "emotion_counts_df = pd.DataFrame.from_dict(emotion_counts, orient='index', columns=['Count']).sort_values('Count', ascending=False)\n",
    "\n",
    "print(\"\\nEmotion distribution:\")\n",
    "print(emotion_counts_df)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=emotion_counts_df.index, y=emotion_counts_df['Count'], palette=\"viridis\")\n",
    "plt.title(\"Emotion Distribution\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Emotion\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.savefig(Path(config.OUTPUT_DIR) / \"emotion_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Utterance Length Distribution (New EDA)\n",
    "balanced_df['utterance_length'] = balanced_df['utterance'].apply(lambda x: len(x.split()))\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(balanced_df['utterance_length'], bins=50, kde=True)\n",
    "plt.title(\"Distribution of Utterance Lengths (Number of Words)\")\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "median_len = balanced_df['utterance_length'].median()\n",
    "mean_len = balanced_df['utterance_length'].mean()\n",
    "plt.axvline(median_len, color='r', linestyle='--', label=f'Median: {median_len:.0f}')\n",
    "plt.axvline(mean_len, color='g', linestyle=':', label=f'Mean: {mean_len:.1f}')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(config.OUTPUT_DIR) / \"utterance_length_distribution.png\")\n",
    "plt.show()\n",
    "print(f\"\\nUtterance Length Stats: Min={balanced_df['utterance_length'].min()}, Max={balanced_df['utterance_length'].max()}, Median={median_len:.0f}, Mean={mean_len:.1f}\")\n",
    "print(f\"Recommendation: Based on max length {balanced_df['utterance_length'].max()}, increasing MAX_LENGTH to 256 seems reasonable if resources allow. Current MAX_LENGTH is {config.MAX_LENGTH}.\")\n",
    "\n",
    "\n",
    "# 3. Label Co-occurrence Heatmap (New EDA)\n",
    "# Calculate co-occurrence matrix\n",
    "co_occurrence_matrix = np.dot(labels.T, labels)\n",
    "# Normalize diagonal to zero for better visualization of off-diagonal elements\n",
    "np.fill_diagonal(co_occurrence_matrix, 0)\n",
    "co_occurrence_df = pd.DataFrame(co_occurrence_matrix, index=label_names, columns=label_names)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(co_occurrence_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Label Co-occurrence Heatmap (excluding self-occurrence)\")\n",
    "plt.xlabel(\"Emotion\")\n",
    "plt.ylabel(\"Emotion\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(config.OUTPUT_DIR) / \"label_cooccurrence.png\")\n",
    "plt.show()\n",
    "\n",
    "# 4. VAD Feature Distribution per Emotion (New EDA)\n",
    "print(\"\\nAnalyzing VAD feature distribution per emotion (might take a moment)...\")\n",
    "vad_df = pd.DataFrame(vad_features, columns=['Valence', 'Arousal', 'Dominance'])\n",
    "emotion_vad_data = []\n",
    "for i, emotion in enumerate(label_names):\n",
    "    # Get indices where this emotion is present\n",
    "    emotion_indices = np.where(labels[:, i] == 1)[0]\n",
    "    if len(emotion_indices) > 0:\n",
    "        emotion_vad_scores = vad_df.iloc[emotion_indices]\n",
    "        for vad_dim in ['Valence', 'Arousal', 'Dominance']:\n",
    "            for score in emotion_vad_scores[vad_dim]:\n",
    "                 # Check for NaN before appending\n",
    "                 if not math.isnan(score):\n",
    "                    emotion_vad_data.append({'Emotion': emotion, 'VAD_Dimension': vad_dim, 'Score': score})\n",
    "\n",
    "if emotion_vad_data: # Check if list is not empty\n",
    "    emotion_vad_df = pd.DataFrame(emotion_vad_data)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    sns.boxplot(x='Emotion', y='Score', hue='VAD_Dimension', data=emotion_vad_df, palette=\"Set2\")\n",
    "    plt.title(\"VAD Score Distribution per Emotion\")\n",
    "    plt.xlabel(\"Emotion\")\n",
    "    plt.ylabel(\"VAD Score\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='VAD Dimension', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(config.OUTPUT_DIR) / \"vad_per_emotion.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Could not generate VAD per emotion plot (likely no VAD scores found).\")\n",
    "\n",
    "print(\"\\n--- End EDA ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Splitting (Stratified) ---\n",
    "print(\"\\nSplitting data...\")\n",
    "X = np.array(utterances)\n",
    "y = labels\n",
    "vad = vad_features # Use the full vad_features array\n",
    "\n",
    "# Using MultilabelStratifiedKFold for robust splitting\n",
    "mskf = MultilabelStratifiedKFold(n_splits=config.N_SPLITS, shuffle=True, random_state=config.RANDOM_STATE)\n",
    "# This ensures stratification across all three sets more reliably than a double split\n",
    "fold_indices = list(mskf.split(X, y))\n",
    "train_idx, temp_idx = fold_indices[0] # Use first fold for initial split\n",
    "X_train, y_train, vad_train = X[train_idx], y[train_idx], vad[train_idx]\n",
    "X_temp, y_temp, vad_temp = X[temp_idx], y[temp_idx], vad[temp_idx]\n",
    "\n",
    "# We will split indices to keep alignment with VAD features\n",
    "temp_indices_range = np.arange(len(X_temp))\n",
    "# Approximate split: 50% validation, 50% test from the temp set\n",
    "val_size = len(temp_indices_range) // 2\n",
    "test_size = len(temp_indices_range) - val_size # Ensure all samples are used\n",
    "\n",
    "# Simple split of indices - less ideal than stratification, but practical here.\n",
    "# For better stratification, one could use skmultilearn's iterative_train_test_split on temp data.\n",
    "np.random.shuffle(temp_indices_range) # Shuffle indices before splitting\n",
    "val_idx_rel = temp_indices_range[:val_size]\n",
    "test_idx_rel = temp_indices_range[val_size:]\n",
    "\n",
    "# Map relative indices back to the original 'temp' data\n",
    "X_val, y_val, vad_val = X_temp[val_idx_rel], y_temp[val_idx_rel], vad_temp[val_idx_rel]\n",
    "X_test, y_test, vad_test = X_temp[test_idx_rel], y_temp[test_idx_rel], vad_temp[test_idx_rel]\n",
    "\n",
    "\n",
    "print(f\"Train set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# --- Check Label Distribution in Splits (Important for low-count emotions) ---\n",
    "print(\"\\nLabel distribution in splits:\")\n",
    "print(\"Train:\", np.sum(y_train, axis=0))\n",
    "print(\"Val:\", np.sum(y_val, axis=0))\n",
    "print(\"Test:\", np.sum(y_test, axis=0))\n",
    "# Verify that all labels have non-zero counts in all splits, especially validation and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset and DataLoader ---\n",
    "print(\"\\nSetting up Dataset and DataLoaders...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts: list, vad_feats: np.ndarray, labels: np.ndarray, tokenizer, max_len: int):\n",
    "        \"\"\"\n",
    "        PyTorch Dataset for emotion classification.\n",
    "\n",
    "        Args:\n",
    "            texts (list): List of utterance strings.\n",
    "            vad_feats (np.ndarray): Array of VAD features.\n",
    "            labels (np.ndarray): Binarized label array.\n",
    "            tokenizer: Hugging Face tokenizer instance.\n",
    "            max_len (int): Maximum sequence length for padding/truncation.\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.vad_feats = vad_feats\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        text = self.texts[idx]\n",
    "        vad = self.vad_feats[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True, # Add [CLS] and [SEP]\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\" # Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        # Remove the batch dimension added by return_tensors=\"pt\"\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['vad'] = torch.tensor(vad, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = EmotionDataset(X_train, vad_train, y_train, tokenizer, config.MAX_LENGTH)\n",
    "val_dataset = EmotionDataset(X_val, vad_val, y_val, tokenizer, config.MAX_LENGTH)\n",
    "test_dataset = EmotionDataset(X_test, vad_test, y_test, tokenizer, config.MAX_LENGTH)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Definition ---\n",
    "class SBERTClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Sentence-BERT based classifier with VAD feature concatenation.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str, num_labels: int, dropout_rate: float):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        #     param.requires_grad = False\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # Input size = SBERT hidden size + VAD features (3)\n",
    "        self.classifier = nn.Linear(self.encoder.config.hidden_size + 3, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, vad):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Use the [CLS] token embedding\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        # Concatenate [CLS] embedding with VAD features\n",
    "        combined = torch.cat((cls_output, vad), dim=1)\n",
    "        combined = self.dropout(combined)\n",
    "        logits = self.classifier(combined)\n",
    "        return logits\n",
    "\n",
    "# --- Loss Function (Weighted) ---\n",
    "\n",
    "epsilon = 1e-6 # To avoid division by zero if a class has 0 positive samples in train\n",
    "pos_counts = np.sum(y_train, axis=0)\n",
    "neg_counts = len(y_train) - pos_counts\n",
    "pos_weights = neg_counts / (pos_counts + epsilon)\n",
    "\n",
    "# Ensure weights are reasonable (e.g., clamp if necessary)\n",
    "# pos_weights = np.clip(pos_weights, 1, 10) # Optional clamping\n",
    "\n",
    "pos_weights_tensor = torch.tensor(pos_weights, dtype=torch.float)\n",
    "print(f\"\\nCalculated positive weights for loss function: {pos_weights_tensor.numpy()}\")\n",
    "\n",
    "# Initialize weighted loss\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights_tensor)\n",
    "\n",
    "\n",
    "# --- Training Setup ---\n",
    "print(\"\\nSetting up training...\")\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device # Accelerator handles device placement\n",
    "\n",
    "model = SBERTClassifier(config.MODEL_NAME, num_labels, config.DROPOUT_RATE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "# Move criterion weights to the correct device\n",
    "criterion.pos_weight = criterion.pos_weight.to(device)\n",
    "\n",
    "# Prepare with Accelerator\n",
    "model, optimizer, train_loader, val_loader, test_loader, criterion = accelerator.prepare(\n",
    "    model, optimizer, train_loader, val_loader, test_loader, criterion\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Loop ---\n",
    "print(\"\\nStarting training...\")\n",
    "train_losses, val_losses, val_f1_macros = [], [], [] # Track macro F1 for validation\n",
    "best_val_metric = -1 # Initialize with -1 for F1-score\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{config.NUM_EPOCHS}\", leave=False)\n",
    "    for batch in train_progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'] # Already on device via accelerator.prepare\n",
    "        attention_mask = batch['attention_mask']\n",
    "        vad = batch['vad'] # Already on device\n",
    "        labels = batch['labels'] # Already on device\n",
    "\n",
    "        logits = model(input_ids, attention_mask, vad)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        train_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    " # --- Validation Loop ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    all_val_preds, all_val_labels = [], []\n",
    "    val_progress_bar = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{config.NUM_EPOCHS}\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in val_progress_bar:\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            vad = batch['vad']\n",
    "            labels = batch['labels']\n",
    "\n",
    "            logits = model(input_ids, attention_mask, vad)\n",
    "            loss = criterion(logits, labels) # Use the same weighted loss for consistency\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Collect predictions and labels across all devices\n",
    "            preds = torch.sigmoid(logits)\n",
    "            gathered_preds = accelerator.gather(preds)\n",
    "            gathered_labels = accelerator.gather(labels)\n",
    "\n",
    "            all_val_preds.append(gathered_preds.cpu().numpy())\n",
    "            all_val_labels.append(gathered_labels.cpu().numpy())\n",
    "\n",
    "            val_progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader) # Note: this might not be perfectly accurate with gather, but gives a trend\n",
    "    val_losses.append(avg_val_loss)\n",
    " # --- Calculate Validation Metrics on Main Process ---\n",
    "    if accelerator.is_main_process:\n",
    "        all_val_preds = np.vstack(all_val_preds)\n",
    "        all_val_labels = np.vstack(all_val_labels).astype(int) # Ensure integer type for metrics\n",
    "        val_preds_binary = (all_val_preds > config.THRESHOLD).astype(int)\n",
    "\n",
    "        # Calculate Macro F1-score for validation, handling zero division\n",
    "        val_f1_macro = f1_score(all_val_labels, val_preds_binary, average='macro', zero_division=0)\n",
    "        val_f1_macros.append(val_f1_macro)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Macro F1: {val_f1_macro:.4f}\")\n",
    "\n",
    "        # Save model based on best validation Macro F1\n",
    "        if val_f1_macro > best_val_metric:\n",
    "            best_val_metric = val_f1_macro\n",
    "            print(f\"*** New best validation Macro F1 found: {best_val_metric:.4f}. Saving model... ***\")\n",
    "            accelerator.wait_for_everyone() # Ensure all processes are ready before saving\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            # Save model state dictionary\n",
    "            torch.save(unwrapped_model.state_dict(), Path(config.CHECKPOINT_DIR) / \"pytorch_model.bin\")\n",
    "            # Save tokenizer\n",
    "            tokenizer.save_pretrained(config.CHECKPOINT_DIR)\n",
    "            # Save MultiLabelBinarizer classes (needed for loading)\n",
    "            np.save(Path(config.CHECKPOINT_DIR) / \"classes.npy\", mlb.classes_)\n",
    "            print(f\"Model saved to {config.CHECKPOINT_DIR}\")\n",
    "\n",
    "# Wait for all processes to finish before proceeding\n",
    "accelerator.wait_for_everyone()\n",
    "print(\"Training finished.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot Training Curves ---\n",
    "if accelerator.is_main_process:\n",
    "    print(\"\\nPlotting training curves...\")\n",
    "    epochs_range = range(1, config.NUM_EPOCHS + 1)\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, train_losses, 'o-', label='Train Loss')\n",
    "    plt.plot(epochs_range, val_losses, 'o-', label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, val_f1_macros, 'o-', label='Validation Macro F1-Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Macro F1-Score')\n",
    "    plt.title('Validation Macro F1-Score over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(config.OUTPUT_DIR) / \"training_curves.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Best Model for Evaluation ---\n",
    "# Address point 1: Re-initializer / Loading the trained model\n",
    "print(\"\\nLoading the best model for evaluation...\")\n",
    "# Load tokenizer\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(config.CHECKPOINT_DIR)\n",
    "\n",
    "# Load label names\n",
    "eval_label_names = np.load(Path(config.CHECKPOINT_DIR) / \"classes.npy\", allow_pickle=True)\n",
    "eval_num_labels = len(eval_label_names)\n",
    "\n",
    "# Instantiate the model architecture\n",
    "eval_model = SBERTClassifier(config.MODEL_NAME, eval_num_labels, config.DROPOUT_RATE)\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model_path = Path(config.CHECKPOINT_DIR) / \"pytorch_model.bin\"\n",
    "if model_path.exists():\n",
    "    state_dict = torch.load(model_path, map_location=accelerator.device) # Load to appropriate device\n",
    "    eval_model.load_state_dict(state_dict)\n",
    "    print(f\"Model weights loaded successfully from {model_path}\")\n",
    "else:\n",
    "    print(f\"ERROR: Model file not found at {model_path}. Cannot evaluate.\")\n",
    "    # Handle error appropriately\n",
    "\n",
    "# Prepare the loaded model with Accelerator (important for multi-GPU inference)\n",
    "eval_model = accelerator.prepare(eval_model)\n",
    "eval_model.eval() # Set to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation on Test Set ---\n",
    "print(\"\\nEvaluating on the test set...\")\n",
    "all_test_preds, all_test_labels = [], []\n",
    "\n",
    "# Ensure test_loader is prepared if not done during training prep\n",
    "prepared_test_loader = accelerator.prepare(test_loader) # Re-prepare if needed\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(prepared_test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        vad = batch['vad']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        # Use the loaded eval_model\n",
    "        logits = eval_model(input_ids, attention_mask, vad)\n",
    "        preds = torch.sigmoid(logits)\n",
    "\n",
    "        # Gather results from all processes\n",
    "        gathered_preds = accelerator.gather(preds)\n",
    "        gathered_labels = accelerator.gather(labels)\n",
    "\n",
    "        all_test_preds.append(gathered_preds.cpu().numpy())\n",
    "        all_test_labels.append(gathered_labels.cpu().numpy())\n",
    "\n",
    "# Process results on the main process\n",
    "if accelerator.is_main_process:\n",
    "    y_true = np.vstack(all_test_labels).astype(int)\n",
    "    y_pred_probs = np.vstack(all_test_preds)\n",
    "    y_pred = (y_pred_probs > config.THRESHOLD).astype(int)\n",
    "\n",
    "    # --- Classification Report ---\n",
    "    print(\"\\nClassification Report (Test Set):\")\n",
    "    # Use output_dict=True for easier parsing if needed later\n",
    "    report = classification_report(y_true, y_pred, target_names=eval_label_names, zero_division=0, output_dict=False)\n",
    "    report_dict = classification_report(y_true, y_pred, target_names=eval_label_names, zero_division=0, output_dict=True)\n",
    "    print(report)\n",
    "    # Save report to file\n",
    "    with open(Path(config.OUTPUT_DIR) / \"classification_report.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    pd.DataFrame(report_dict).transpose().to_csv(Path(config.OUTPUT_DIR) / \"classification_report.csv\")\n",
    "\n",
    "\n",
    "    # --- Combined Confusion Matrix (Summation Approach) ---\n",
    "    # Calculate summed TP, FP, FN, TN across all labels\n",
    "    mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "    # mcm gives [[TN, FP], [FN, TP]] for each label\n",
    "    total_tn = np.sum(mcm[:, 0, 0])\n",
    "    total_fp = np.sum(mcm[:, 0, 1])\n",
    "    total_fn = np.sum(mcm[:, 1, 0])\n",
    "    total_tp = np.sum(mcm[:, 1, 1])\n",
    "\n",
    "    # Create the combined 2x2 matrix\n",
    "    combined_cm = np.array([[total_tn, total_fp],\n",
    "                            [total_fn, total_tp]])\n",
    "\n",
    "    print(\"\\nCombined Confusion Matrix (Summed across labels):\")\n",
    "    print(f\"[[TN={total_tn}, FP={total_fp}]\")\n",
    "    print(f\" [FN={total_fn}, TP={total_tp}]]\")\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(combined_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "                yticklabels=[\"True Negative\", \"True Positive\"])\n",
    "    plt.title(\"Combined Confusion Matrix (Summed)\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(config.OUTPUT_DIR) / \"combined_confusion_matrix.png\")\n",
    "    plt.show()\n",
    "    print(\"Note: This 'combined' matrix sums counts across all labels. Interpret with caution, as it aggregates diverse label performances.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Per-Emotion Metrics Heatmap ---\n",
    "# (Your original code for this is good, kept for detailed view)\n",
    "if accelerator.is_main_process: # Added indentation to place the per-emotion metric calculation inside the if block.\n",
    "    precision_per_class = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    recall_per_class = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1_per_class = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"Precision\": precision_per_class,\n",
    "        \"Recall\": recall_per_class,\n",
    "        \"F1-Score\": f1_per_class\n",
    "    }, index=eval_label_names)\n",
    "\n",
    "    plt.figure(figsize=(12, max(6, len(eval_label_names) * 0.3))) # Adjust height based on number of labels\n",
    "    sns.heatmap(metrics_df, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "    plt.title(\"Per-Emotion Evaluation Metrics (Test Set)\")\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(config.OUTPUT_DIR) / \"per_emotion_metrics_heatmap.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # --- Save Individual Confusion Matrices to PDF ---\n",
    "    # (Your original code is good, just updating paths)\n",
    "    pdf_path = Path(config.OUTPUT_DIR) / config.PDF_FILENAME\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        # Plot Combined CM first\n",
    "        fig_comb = plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(combined_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Predicted Negative\", \"Predicted Positive\"],\n",
    "                    yticklabels=[\"True Negative\", \"True Positive\"])\n",
    "        plt.title(\"Combined Confusion Matrix (Summed)\")\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig_comb)\n",
    "        plt.close(fig_comb)\n",
    "\n",
    "        # Plot Per-Emotion Metrics Heatmap\n",
    "        fig_metrics = plt.figure(figsize=(12, max(6, len(eval_label_names) * 0.3)))\n",
    "        sns.heatmap(metrics_df, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "        plt.title(\"Per-Emotion Evaluation Metrics (Test Set)\")\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig(fig_metrics)\n",
    "        plt.close(fig_metrics)\n",
    "\n",
    "        # Plot Individual CMs\n",
    "        for idx, label in enumerate(eval_label_names):\n",
    "            cm = mcm[idx] # Get the matrix for this label\n",
    "            fig_indiv = plt.figure(figsize=(4, 4))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                        xticklabels=[f\"Not '{label}'\", f\"'{label}'\"],\n",
    "                        yticklabels=[f\"Not '{label}'\", f\"'{label}'\"])\n",
    "            plt.title(f\"Confusion Matrix for '{label}'\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.tight_layout()\n",
    "            pdf.savefig(fig_indiv)\n",
    "            plt.close(fig_indiv)\n",
    "\n",
    "    print(f\"Evaluation plots saved to {pdf_path}\")\n",
    "    # Optional download for Colab\n",
    "    files.download(str(pdf_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prediction Function ---\n",
    "\n",
    "def predict_emotions(text: str, model, tokenizer, vad_lexicon, label_names, device, max_len: int, threshold: float = 0.5, pretty_print: bool = False, show_table: bool = False):\n",
    "    \"\"\"\n",
    "    Predicts emotions for a given text using the trained model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text utterance.\n",
    "        model: The trained SBERTClassifier model (already on the correct device).\n",
    "        tokenizer: The corresponding Hugging Face tokenizer.\n",
    "        vad_lexicon: The NRC-VAD lexicon DataFrame.\n",
    "        label_names (list): List of emotion label names.\n",
    "        device: The torch device to run inference on.\n",
    "        max_len (int): Max sequence length for tokenization.\n",
    "        threshold (float): Probability threshold for classifying an emotion as present.\n",
    "        pretty_print (bool): Whether to print the output nicely formatted.\n",
    "        show_table (bool): Whether to display the top 5 emotions as a table (requires IPython/Jupyter).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing predicted emotions (> threshold) and top 5 probabilities.\n",
    "    \"\"\"\n",
    "    model.eval() # Ensure model is in eval mode\n",
    "\n",
    "    # Compute NRC-VAD features\n",
    "    # Use the same function as in preprocessing for consistency\n",
    "    vad_feat_np = compute_vad_features(text, vad_lexicon)\n",
    "    vad_feat = torch.tensor(vad_feat_np, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\", # Pad to max_length for consistent input size\n",
    "        max_length=max_len\n",
    "    ).to(device)\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(encoding['input_ids'], encoding['attention_mask'], vad_feat)\n",
    "        probs = torch.sigmoid(logits).squeeze(0).cpu().numpy() # Get probabilities for the single input\n",
    "\n",
    "    # Emotions with probability > threshold\n",
    "    predicted_indices = np.where(probs > threshold)[0]\n",
    "    predicted_emotions_dict = {\n",
    "        label_names[i]: float(probs[i])\n",
    "        for i in predicted_indices\n",
    "    }\n",
    "\n",
    "    # Top 5 probable emotions regardless of threshold\n",
    "    top_5_indices = probs.argsort()[-5:][::-1] # Get indices of top 5 probabilities\n",
    "    top_5_emotions_list = [\n",
    "        {\"Emotion\": label_names[i], \"Probability\": round(float(probs[i]), 4)}\n",
    "        for i in top_5_indices\n",
    "    ]\n",
    "\n",
    "    result = {\n",
    "        \"input_text\": text,\n",
    "        \"predicted_emotions\": predicted_emotions_dict,\n",
    "        \"top_5_probabilities\": top_5_emotions_list\n",
    "    }\n",
    "\n",
    "    if pretty_print:\n",
    "        print(json.dumps(result, indent=4))\n",
    "\n",
    "    if show_table:\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            df = pd.DataFrame(top_5_emotions_list)\n",
    "            print(\"\\nTop 5 Probable Emotions:\")\n",
    "            display(df)\n",
    "        except ImportError:\n",
    "            print(\"Cannot display table. IPython is not available.\")\n",
    "            print(top_5_emotions_list) # Fallback to printing the list\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Prediction (using the loaded model) ---\n",
    "if accelerator.is_main_process:\n",
    "    print(\"\\nExample Prediction:\")\n",
    "    example_text = \"Though I smiled and congratulated her on the promotion, deep down I couldn't shake the bitter sting of being overlooked once again — a mix of admiration, envy, and quiet despair churned within me.\"\n",
    "    prediction_result = predict_emotions(\n",
    "        text=example_text,\n",
    "        model=eval_model,\n",
    "        tokenizer=eval_tokenizer,\n",
    "        vad_lexicon=nrc_vad,\n",
    "        label_names=eval_label_names,\n",
    "        device=accelerator.device,\n",
    "        max_len=config.MAX_LENGTH,\n",
    "        threshold=config.THRESHOLD,\n",
    "        pretty_print=False,\n",
    "        show_table=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Prediction (using the loaded model) ---\n",
    "if accelerator.is_main_process:\n",
    "    print(\"\\nExample Prediction:\")\n",
    "    example_text = \"I stopped expecting apologies a long time ago — silence speaks louder, and disappointment eventually becomes routine.\"\n",
    "    prediction_result = predict_emotions(\n",
    "        text=example_text,\n",
    "        model=eval_model,\n",
    "        tokenizer=eval_tokenizer,\n",
    "        vad_lexicon=nrc_vad,\n",
    "        label_names=eval_label_names,\n",
    "        device=accelerator.device,\n",
    "        max_len=config.MAX_LENGTH,\n",
    "        threshold=config.THRESHOLD,\n",
    "        pretty_print=False,\n",
    "        show_table=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Prediction (using the loaded model) ---\n",
    "if accelerator.is_main_process:\n",
    "    print(\"\\nExample Prediction:\")\n",
    "    example_text = \"I woke up to the sound of birds, the sun gently shining through my window, and a heart full of gratitude — today just feels beautifully right.\"\n",
    "    prediction_result = predict_emotions(\n",
    "        text=example_text,\n",
    "        model=eval_model,\n",
    "        tokenizer=eval_tokenizer,\n",
    "        vad_lexicon=nrc_vad,\n",
    "        label_names=eval_label_names,\n",
    "        device=accelerator.device,\n",
    "        max_len=config.MAX_LENGTH,\n",
    "        threshold=config.THRESHOLD,\n",
    "        pretty_print=False,\n",
    "        show_table=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save and Download Final Model ---\n",
    "if accelerator.is_main_process:\n",
    "    print(\"\\nZipping the best model checkpoint...\")\n",
    "    # The best model is already saved in config.CHECKPOINT_DIR during training\n",
    "    zip_path = Path(config.OUTPUT_DIR) / config.MODEL_ZIP_FILENAME\n",
    "    # Use python's zipfile module for better control\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        checkpoint_path = Path(config.CHECKPOINT_DIR)\n",
    "        for file_path in checkpoint_path.rglob('*'):\n",
    "            zipf.write(file_path, file_path.relative_to(checkpoint_path))\n",
    "    print(f\"Model checkpoint zipped to {zip_path}\")\n",
    "\n",
    "    #  download in Colab\n",
    "    try: # Fixed indentation here\n",
    "        files.download(str(zip_path))\n",
    "        print(f\"Initiated download for {config.MODEL_ZIP_FILENAME}\")\n",
    "    except NameError:\n",
    "        print(\"Skipping automatic download (not in Colab environment).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUDti4_b-lKr"
   },
   "source": [
    "# **Re-intialize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class CustomSBERTClassifier(torch.nn.Module):\n",
    "    \"\"\"Modified SBERT-based emotion classifier with VAD features that matches your model structure\"\"\"\n",
    "    def __init__(self, model_name, num_labels, vad_features_dim=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # The main difference is here - we're using 'encoder' as the attribute name, not 'sbert'\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.encoder.config.hidden_size\n",
    "\n",
    "        # Combined features: SBERT + VAD\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size + vad_features_dim, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, vad_features):\n",
    "        # Get SBERT embeddings using the encoder\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "\n",
    "        # Concatenate SBERT embeddings with VAD features\n",
    "        combined_features = torch.cat([pooled_output, vad_features], dim=1)\n",
    "\n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(combined_features)\n",
    "        return logits\n",
    "\n",
    "def load_vad_lexicon(file_path):\n",
    "    \"\"\"Load NRC VAD Lexicon from file with flexible column handling\"\"\"\n",
    "    try:\n",
    "        # Try to read the file first to examine its structure\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "        print(f\"VAD lexicon columns: {df.columns.tolist()}\")\n",
    "\n",
    "        # Set the first column as the index\n",
    "        df = df.set_index(df.columns[0])\n",
    "\n",
    "        # Verify we have the expected structure (at least 3 columns for V, A, D)\n",
    "        if len(df.columns) < 3:\n",
    "            raise ValueError(f\"VAD lexicon has insufficient columns: {df.columns}\")\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to parse VAD lexicon file: {e}. Please check the file format.\")\n",
    "\n",
    "def compute_vad_features(text, vad_lexicon):\n",
    "    \"\"\"Compute VAD (Valence, Arousal, Dominance) features for the input text\"\"\"\n",
    "    # Lowercasing and basic tokenization\n",
    "    words = text.lower().split()\n",
    "\n",
    "    # Print lexicon columns to debug\n",
    "    vad_columns = vad_lexicon.columns.tolist()\n",
    "    print(f\"VAD lexicon columns available: {vad_columns}\")\n",
    "\n",
    "    # Initialize VAD scores - use the first three columns whatever they're called\n",
    "    v_scores, a_scores, d_scores = [], [], []\n",
    "\n",
    "    # Collect VAD scores for words in the lexicon\n",
    "    for word in words:\n",
    "        if word in vad_lexicon.index:\n",
    "            # Use the first three columns for V, A, D respectively\n",
    "            v_scores.append(float(vad_lexicon.loc[word, vad_columns[0]]))\n",
    "            a_scores.append(float(vad_lexicon.loc[word, vad_columns[1]]))\n",
    "            d_scores.append(float(vad_lexicon.loc[word, vad_columns[2]]))\n",
    "\n",
    "    # Calculate averages (with fallback to neutral 0.5 if no words found)\n",
    "    v_avg = sum(v_scores) / len(v_scores) if v_scores else 0.5\n",
    "    a_avg = sum(a_scores) / len(a_scores) if a_scores else 0.5\n",
    "    d_avg = sum(d_scores) / len(d_scores) if d_scores else 0.5\n",
    "\n",
    "    return [v_avg, a_avg, d_avg]\n",
    "\n",
    "def predict_emotions(text, model, tokenizer, vad_lexicon, label_names, device, max_len=128, threshold=0.5, pretty_print=False, show_table=False):\n",
    "    \"\"\"\n",
    "    Predicts emotions for a given text using the trained model.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import numpy as np\n",
    "\n",
    "    model.eval()  # Ensure model is in eval mode\n",
    "\n",
    "    # Compute NRC-VAD features\n",
    "    vad_feat_np = compute_vad_features(text, vad_lexicon)\n",
    "    vad_feat = torch.tensor(vad_feat_np, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_len\n",
    "    ).to(device)\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(encoding['input_ids'], encoding['attention_mask'], vad_feat)\n",
    "        probs = torch.sigmoid(logits).squeeze(0).cpu().numpy()\n",
    "\n",
    "    # Emotions with probability > threshold\n",
    "    predicted_indices = np.where(probs > threshold)[0]\n",
    "    predicted_emotions_dict = {\n",
    "        label_names[i]: float(probs[i])\n",
    "        for i in predicted_indices\n",
    "    }\n",
    "\n",
    "    # Top 5 probable emotions regardless of threshold\n",
    "    top_5_indices = probs.argsort()[-5:][::-1]\n",
    "    top_5_emotions_list = [\n",
    "        {\"Emotion\": label_names[i], \"Probability\": round(float(probs[i]), 4)}\n",
    "        for i in top_5_indices\n",
    "    ]\n",
    "\n",
    "    result = {\n",
    "        \"input_text\": text,\n",
    "        \"predicted_emotions\": predicted_emotions_dict,\n",
    "        \"top_5_probabilities\": top_5_emotions_list\n",
    "    }\n",
    "\n",
    "    if pretty_print:\n",
    "        print(json.dumps(result, indent=4))\n",
    "\n",
    "    if show_table:\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            df = pd.DataFrame(top_5_emotions_list)\n",
    "            print(\"\\nTop 5 Probable Emotions:\")\n",
    "            display(df)\n",
    "        except ImportError:\n",
    "            print(\"Cannot display table. IPython is not available.\")\n",
    "            print(top_5_emotions_list)\n",
    "\n",
    "    return result\n",
    "\n",
    "def reinitialize_from_checkpoint(\n",
    "    model_dir=\"best_model\",\n",
    "    vad_lexicon_path=\"NRC-VAD-Lexicon.txt\",\n",
    "    max_len=128,\n",
    "    threshold=0.5,\n",
    "    device=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Reinitializes the emotion detection model from existing checkpoint files.\n",
    "    Modified to handle the different model structure with 'encoder' prefix.\n",
    "    \"\"\"\n",
    "    # Set device\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Convert model_dir to Path\n",
    "    model_path = Path(model_dir)\n",
    "\n",
    "    # Check if model directory exists\n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"Model directory not found: {model_path}\")\n",
    "\n",
    "    # Check required files\n",
    "    required_files = [\n",
    "        \"pytorch_model.bin\",\n",
    "        \"classes.npy\"\n",
    "    ]\n",
    "\n",
    "    optional_tokenizer_files = [\n",
    "        \"special_tokens_map.json\",\n",
    "        \"tokenizer.json\",\n",
    "        \"tokenizer_config.json\",\n",
    "        \"vocab.txt\"\n",
    "    ]\n",
    "\n",
    "    missing_files = []\n",
    "    for file in required_files:\n",
    "        if not (model_path / file).exists():\n",
    "            missing_files.append(file)\n",
    "\n",
    "    if missing_files:\n",
    "        raise FileNotFoundError(f\"Required files not found: {', '.join(missing_files)}\")\n",
    "\n",
    "    # Load emotion labels from classes.npy\n",
    "    label_names = np.load(model_path / \"classes.npy\", allow_pickle=True).tolist()\n",
    "    num_labels = len(label_names)\n",
    "\n",
    "    # Check if tokenizer files exist in the directory\n",
    "    has_tokenizer_files = all((model_path / file).exists() for file in optional_tokenizer_files)\n",
    "\n",
    "    # Load tokenizer - either from saved files or default\n",
    "    if has_tokenizer_files:\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "            print(\"Loaded tokenizer from saved files\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading tokenizer from files: {e}\")\n",
    "            print(\"Falling back to default tokenizer\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    else:\n",
    "        print(\"Tokenizer files not found, using default\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Determine the base model name\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"  # Default\n",
    "    if (model_path / \"tokenizer_config.json\").exists():\n",
    "        try:\n",
    "            with open(model_path / \"tokenizer_config.json\", \"r\") as f:\n",
    "                tokenizer_config = json.load(f)\n",
    "            config_model_name = tokenizer_config.get(\"name_or_path\")\n",
    "            if config_model_name:\n",
    "                model_name = config_model_name\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading tokenizer config: {e}\")\n",
    "\n",
    "    # Initialize model architecture with modified class\n",
    "    model = CustomSBERTClassifier(\n",
    "        model_name=model_name,\n",
    "        num_labels=num_labels,\n",
    "        vad_features_dim=3\n",
    "    )\n",
    "\n",
    "    # Load saved model weights\n",
    "    try:\n",
    "        state_dict = torch.load(model_path / \"pytorch_model.bin\", map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(\"Model weights loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading state dict directly: {e}\")\n",
    "        print(\"Attempting to fix state dict keys...\")\n",
    "\n",
    "        # Load state dict and modify keys if needed\n",
    "        state_dict = torch.load(model_path / \"pytorch_model.bin\", map_location=device)\n",
    "\n",
    "        # Check if we need to apply any key transformations\n",
    "        sample_keys = list(state_dict.keys())[:5]\n",
    "        print(f\"Sample keys in saved model: {sample_keys}\")\n",
    "\n",
    "        # Create a new state dict with correct keys if needed\n",
    "        new_state_dict = {}\n",
    "        for key, value in state_dict.items():\n",
    "            # Handle possible key patterns\n",
    "            if key.startswith('encoder.'):\n",
    "                # Expected pattern for our CustomSBERTClassifier\n",
    "                new_key = key\n",
    "            elif key.startswith('sbert.'):\n",
    "                # Convert sbert.* to encoder.*\n",
    "                new_key = key.replace('sbert.', 'encoder.')\n",
    "            else:\n",
    "                # Keep as is for other keys (like classifier)\n",
    "                new_key = key\n",
    "\n",
    "            new_state_dict[new_key] = value\n",
    "\n",
    "        # Try loading with the modified state dict\n",
    "        try:\n",
    "            model.load_state_dict(new_state_dict)\n",
    "            print(\"Model loaded successfully with modified state dict\")\n",
    "        except Exception as nested_e:\n",
    "            print(f\"Error loading with modified keys: {nested_e}\")\n",
    "            print(\"\\nModel key structure might be different. Attempting to create a compatible model...\")\n",
    "\n",
    "            # As a last resort, create a model that matches the state dict structure\n",
    "            class_keys = [k for k in state_dict.keys() if 'classifier' in k]\n",
    "            if class_keys:\n",
    "                print(f\"Found classifier keys: {class_keys}\")\n",
    "            else:\n",
    "                print(\"No classifier keys found in state dict\")\n",
    "\n",
    "            # This part might need customization based on the exact model structure\n",
    "            input_dim = None\n",
    "            output_dim = None\n",
    "\n",
    "            if len(class_keys) > 0:\n",
    "                classifier_weight_key = [k for k in class_keys if 'weight' in k]\n",
    "                if classifier_weight_key:\n",
    "                    weight_shape = state_dict[classifier_weight_key[0]].shape\n",
    "                    input_dim = weight_shape[0]\n",
    "                    output_dim = weight_shape[1]\n",
    "                    print(f\"Detected classifier dimensions: input={input_dim}, output={output_dim}\")\n",
    "\n",
    "            # Create a minimal model that just loads the classifier weights\n",
    "            # This is a fallback that might work if the SBERT part is missing or incompatible\n",
    "            if input_dim is not None and output_dim is not None:\n",
    "                class MinimalModel(torch.nn.Module):\n",
    "                    def __init__(self, input_dim, output_dim):\n",
    "                        super().__init__()\n",
    "                        self.classifier = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "                    def forward(self, input_ids, attention_mask, vad_features):\n",
    "                        # This is just a placeholder implementation\n",
    "                        # It won't work correctly but allows loading the weights\n",
    "                        return self.classifier(torch.zeros(1, input_dim).to(input_ids.device))\n",
    "\n",
    "                model = MinimalModel(input_dim, output_dim)\n",
    "                try:\n",
    "                    # Try to load just the classifier weights\n",
    "                    classifier_dict = {k: v for k, v in state_dict.items() if 'classifier' in k}\n",
    "                    model.load_state_dict(classifier_dict, strict=False)\n",
    "                    print(\"Warning: Only classifier weights loaded. Model may not function correctly.\")\n",
    "                except Exception as e3:\n",
    "                    print(f\"Failed to load even minimal model: {e3}\")\n",
    "                    raise RuntimeError(\"Could not load the model with any method. Model structure might be incompatible.\")\n",
    "            else:\n",
    "                raise RuntimeError(\"Could not determine model dimensions from state dict\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Load VAD lexicon with more detailed debugging\n",
    "    try:\n",
    "        print(f\"Attempting to load VAD lexicon from {vad_lexicon_path}\")\n",
    "        vad_lexicon = load_vad_lexicon(vad_lexicon_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading VAD lexicon from {vad_lexicon_path}: {e}\")\n",
    "        # Try to find it in the model directory\n",
    "        alternative_path = model_path / \"NRC-VAD-Lexicon.txt\"\n",
    "        print(f\"Trying alternative path: {alternative_path}\")\n",
    "        if alternative_path.exists():\n",
    "            try:\n",
    "                vad_lexicon = load_vad_lexicon(alternative_path)\n",
    "            except Exception as e2:\n",
    "                print(f\"Error loading from alternative path: {e2}\")\n",
    "                raise\n",
    "        else:\n",
    "            print(f\"VAD lexicon not found at alternative path: {alternative_path}\")\n",
    "            raise FileNotFoundError(\n",
    "                f\"VAD lexicon not found at {vad_lexicon_path} or {alternative_path}. \"\n",
    "                \"Please download it from http://saifmohammad.com/WebPages/nrc-vad.html\"\n",
    "            )\n",
    "\n",
    "    # Create config dictionary for convenience\n",
    "    config = {\n",
    "        \"model_dir\": str(model_path),\n",
    "        \"max_length\": max_len,\n",
    "        \"threshold\": threshold,\n",
    "        \"device\": device,\n",
    "        \"num_emotions\": num_labels\n",
    "    }\n",
    "\n",
    "    print(f\"Emotion detection model successfully loaded from {model_path}\")\n",
    "    print(f\"Model contains {num_labels} emotion labels: {', '.join(label_names[:5])}{'...' if len(label_names) > 5 else ''}\")\n",
    "    print(f\"Using threshold: {threshold}\")\n",
    "    print(f\"Running on device: {device}\")\n",
    "\n",
    "    return model, tokenizer, vad_lexicon, label_names, config\n",
    "\n",
    "def extract_model_zip(zip_path, extract_dir=None, overwrite=False):\n",
    "    \"\"\"\n",
    "    Extract the model zip file to the specified directory.\n",
    "\n",
    "    Args:\n",
    "        zip_path (str): Path to the zip file containing model files\n",
    "        extract_dir (str, optional): Directory to extract files to. If None, extracts to a directory named after the zip file\n",
    "        overwrite (bool): Whether to overwrite existing files\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the extracted directory\n",
    "    \"\"\"\n",
    "    import zipfile\n",
    "    import shutil\n",
    "\n",
    "    zip_path = Path(zip_path)\n",
    "\n",
    "    # If no extract_dir specified, use the zip filename without extension\n",
    "    if extract_dir is None:\n",
    "        extract_dir = zip_path.stem\n",
    "\n",
    "    extract_path = Path(extract_dir)\n",
    "\n",
    "    # Check if directory already exists\n",
    "    if extract_path.exists():\n",
    "        if overwrite:\n",
    "            print(f\"Removing existing directory: {extract_path}\")\n",
    "            shutil.rmtree(extract_path)\n",
    "        else:\n",
    "            print(f\"Directory already exists: {extract_path}\")\n",
    "            return str(extract_path)\n",
    "\n",
    "    # Create extraction directory\n",
    "    extract_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Extract files\n",
    "    print(f\"Extracting {zip_path} to {extract_path}\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "    # Check if files are nested in a subdirectory\n",
    "    contents = list(extract_path.iterdir())\n",
    "    if len(contents) == 1 and contents[0].is_dir():\n",
    "        # If there's only one subdirectory, move its contents up\n",
    "        subdir = contents[0]\n",
    "        for item in subdir.iterdir():\n",
    "            # Move each item to the parent directory\n",
    "            shutil.move(str(item), str(extract_path))\n",
    "        # Remove the now-empty subdirectory\n",
    "        subdir.rmdir()\n",
    "\n",
    "    return str(extract_path)\n",
    "\n",
    "def initialize_emotion_model(\n",
    "    model_zip_path=\"best_model.zip\",\n",
    "    vad_lexicon_path=\"NRC-VAD-Lexicon.txt\",\n",
    "    extract_dir=None,\n",
    "    overwrite_extract=False,\n",
    "    max_len=128,\n",
    "    threshold=0.5,\n",
    "    device=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete function to extract and initialize the emotion model in one step.\n",
    "    \"\"\"\n",
    "    import zipfile\n",
    "\n",
    "    # Check if model_zip_path is a zip file or directory\n",
    "    model_zip_path = Path(model_zip_path)\n",
    "\n",
    "    if model_zip_path.is_file() and zipfile.is_zipfile(model_zip_path):\n",
    "        # Extract the zip file\n",
    "        model_dir = extract_model_zip(\n",
    "            zip_path=model_zip_path,\n",
    "            extract_dir=extract_dir,\n",
    "            overwrite=overwrite_extract\n",
    "        )\n",
    "    else:\n",
    "        # Use as directory directly\n",
    "        model_dir = str(model_zip_path)\n",
    "\n",
    "    # Initialize from the extracted directory\n",
    "    return reinitialize_from_checkpoint(\n",
    "        model_dir=model_dir,\n",
    "        vad_lexicon_path=vad_lexicon_path,\n",
    "        max_len=max_len,\n",
    "        threshold=threshold,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "# Additional function to inspect and debug lexicon format\n",
    "def inspect_vad_lexicon(file_path):\n",
    "    \"\"\"Inspect the format of the VAD lexicon file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            # Read first few lines\n",
    "            print(\"First 5 lines of the lexicon file:\")\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 5:\n",
    "                    print(f\"Line {i+1}: {line.strip()}\")\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        # Try different parsing approaches\n",
    "        print(\"\\nAttempting to parse with different methods:\")\n",
    "\n",
    "        # Method 1: Tab-separated with header\n",
    "        try:\n",
    "            df1 = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "            print(f\"Method 1 (tab-separated with header): Columns = {df1.columns.tolist()}, Shape = {df1.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Method 1 failed: {e}\")\n",
    "\n",
    "        # Method 2: Tab-separated without header\n",
    "        try:\n",
    "            df2 = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "            print(f\"Method 2 (tab-separated without header): Columns = {df2.columns.tolist()}, Shape = {df2.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Method 2 failed: {e}\")\n",
    "\n",
    "        # Method 3: Auto-detect separator\n",
    "        try:\n",
    "            df3 = pd.read_csv(file_path, sep=None, engine='python')\n",
    "            print(f\"Method 3 (auto-detect separator): Columns = {df3.columns.tolist()}, Shape = {df3.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Method 3 failed: {e}\")\n",
    "\n",
    "        return \"Lexicon inspection complete\"\n",
    "    except Exception as e:\n",
    "        return f\"Error inspecting lexicon: {e}\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # First, inspect the lexicon to understand its format\n",
    "        lexicon_path = \"NRC-VAD-Lexicon.txt\"\n",
    "        inspect_result = inspect_vad_lexicon(lexicon_path)\n",
    "        print(inspect_result)\n",
    "\n",
    "        # Initialize model from zip file or directory\n",
    "        model, tokenizer, vad_lexicon, label_names, config = initialize_emotion_model(\n",
    "            model_zip_path=\"best_model\",  # Or \"best_model.zip\" if compressed\n",
    "            vad_lexicon_path=lexicon_path,\n",
    "            threshold=0.5,\n",
    "            max_len=128\n",
    "        )\n",
    "\n",
    "        # Test prediction\n",
    "        example_text = \"I'm absolutely thrilled with my recent promotion! After years of hard work and dedication, seeing my efforts recognized fills me with incredible joy and satisfaction. This achievement has given me renewed confidence and enthusiasm for tackling future challenges. I can't wait to celebrate this milestone with my loved ones who have supported me throughout this journey.\"\n",
    "\n",
    "        prediction = predict_emotions(\n",
    "            text=example_text,\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            vad_lexicon=vad_lexicon,\n",
    "            label_names=label_names,\n",
    "            device=config[\"device\"],\n",
    "            max_len=config[\"max_length\"],\n",
    "            threshold=config[\"threshold\"],\n",
    "            pretty_print=True,\n",
    "            show_table=True\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
